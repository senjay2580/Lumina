# 提示词采集系统 - 快速开始

## 部署清单

### ✅ 第一步：数据库迁移

在 Supabase SQL Editor 中执行：

```sql
-- 执行 supabase/plus/024_add_crawl_logs.sql
```

这会创建 `crawl_logs` 表用于记录详细日志。

### ✅ 第二步：部署 Edge Function

```bash
supabase functions deploy prompt-crawler
```

### ✅ 第三步：验证部署

1. 进入应用的 "提示词采集" 页面
2. 点击 "立即采集" 按钮
3. 点击 "查看进度" 查看实时日志

## 新功能说明

### 🔄 实时进度显示

采集时会显示：
- 发现的来源数量
- 新增的来源数量
- 提取的提示词数量
- 详细的操作日志

### 📋 详细日志

每条日志包含：
- 时间戳
- 日志级别 (信息/警告/错误)
- 详细信息
- 相关数据

### 🔁 失败重试

- 采集失败时自动记录错误
- 在任务历史中显示 "重试" 按钮
- 一键重新启动采集

### 🛡️ 反爬虫保护

系统已优化以避免被限制：
- 真实的浏览器 User-Agent
- 随机延迟 (1-3 秒)
- 自动重试机制
- 指数退避策略

## 常见操作

### 启动采集

```
1. 点击 "立即采集" 按钮
2. 选择采集类型 (Reddit/GitHub/全部)
3. 等待采集完成
```

### 查看进度

```
1. 采集启动后，点击 "查看进度" 按钮
2. 查看实时统计信息
3. 展开 "详细日志" 查看完整日志
```

### 重试失败的采集

```
1. 进入 "爬取历史" 标签页
2. 找到状态为 "failed" 的任务
3. 点击 "重试" 按钮
```

### 查看采集结果

```
1. 进入 "待审核" 标签页查看新提取的提示词
2. 审核通过后进入 "已审核" 标签页
3. 选择分类后导入到提示词库
```

## 配置调整

在 "配置" 标签页可以调整：

| 配置项 | 说明 | 默认值 |
|--------|------|--------|
| Reddit 子版块 | 要爬取的 Reddit 子版块 | ChatGPT, PromptEngineering 等 |
| GitHub 搜索关键词 | GitHub 搜索关键词 | prompt engineering 等 |
| Reddit 最低分数 | 只爬取分数 >= 此值的帖子 | 10 |
| GitHub 最低 Stars | 只爬取 Stars >= 此值的仓库 | 50 |
| AI 质量阈值 | 只导入评分 >= 此值的提示词 | 6.0 |

## 故障排查

### 采集失败

**症状**: 采集任务显示 "failed" 状态

**解决方案**:
1. 点击 "查看进度" 查看详细日志
2. 查看错误信息，常见原因：
   - API 密钥配置错误
   - 网络连接问题
   - API 配额已用尽
3. 修复问题后点击 "重试"

### 没有提取到提示词

**症状**: 采集完成但 "待审核" 为空

**解决方案**:
1. 检查 AI 质量阈值是否过高
2. 检查 Reddit/GitHub 的搜索关键词是否合适
3. 尝试降低最低分数/Stars 阈值
4. 在配置中调整参数后重新采集

### 采集速度慢

**症状**: 采集耗时很长

**原因**: 这是正常的，系统添加了随机延迟以避免被限制

**优化方案**:
- 减少搜索关键词数量
- 增加最低分数/Stars 阈值
- 在非高峰时段采集

## 监控和维护

### 定期检查

- 每周检查一次采集成功率
- 监控提取的提示词质量
- 调整配置参数以优化结果

### 清理日志

日志表会随时间增长，可以定期清理：

```sql
-- 删除 30 天前的日志
DELETE FROM crawl_logs 
WHERE created_at < NOW() - INTERVAL '30 days';
```

### 监控成本

- Reddit API: 免费
- GitHub API: 免费 (使用 Token)
- OpenAI: 约 $0.001-0.005 per 分析
- 月成本估算: $3-15 (100 条/天)

## 获取帮助

查看详细文档：
- `docs/prompt-crawler-setup.md` - 部署指南
- `docs/prompt-crawler-improvements.md` - 改进说明
- `docs/prompt-crawler-design.md` - 系统设计

## 下一步

1. ✅ 部署系统
2. ✅ 配置 API 密钥
3. ✅ 启动第一次采集
4. ✅ 审核和导入提示词
5. ✅ 根据需要调整配置

祝你使用愉快！🎉
